{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Salary Survey from data taken from StackOverFlow\n",
    "\n",
    "## Use of Accumulators will be emphasized in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class Utils():\n",
    "    Comma_Delim = re.compile(''',(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find these things:\n",
    "###### 1. Total number of records\n",
    "###### 2. Number of records for country Argentina\n",
    "###### 3. Number of records with missing salary\n",
    "\n",
    "##### here the power of accumulator is realized: these are write-only variables and used for aggregating information across Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "total_record = sc.accumulator(0)\n",
    "missingSalary = sc.accumulator(0)\n",
    "#@@@@@\n",
    "bytesProcessed =sc.accumulator(0)\n",
    "#@@@@@\n",
    "record_file = sc.textFile(\"in/2016-stack-overflow-survey-responses.csv\")\n",
    "#print(\"{}\".format(total_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Employee in Argentina: 146\n",
      "Total Employee Across the dataset: 2000\n",
      "Employee with missing Salary: 566\n",
      "Total bytes Processed: 2360248\n"
     ]
    }
   ],
   "source": [
    "def inArgentina(response:str):\n",
    "    global total_record, missingSalary,bytesProcessed\n",
    "    \n",
    "    split = Utils.Comma_Delim.split(response)\n",
    "    total_record+=1\n",
    "    #@@@@@\n",
    "    bytesProcessed+=len(response.encode(\"UTF-8\"))\n",
    "    #@@@@@\n",
    "    if not split[14]:\n",
    "        missingSalary+=1\n",
    "    if split[2]==\"Argentina\":\n",
    "        return response\n",
    "\n",
    "#print(\"{}\".format(total_record))    \n",
    "    \n",
    "responseForArgentina = record_file.filter(inArgentina)\n",
    "#total_Argentina_employee = responseForArgentina.count()\n",
    "print(\"Total Employee in Argentina: {}\".format(responseForArgentina.count()))\n",
    "print(\"Total Employee Across the dataset: {}\".format(total_record.value))\n",
    "print(\"Employee with missing Salary: {}\".format(missingSalary.value))\n",
    "\n",
    "#@@@@@@@\n",
    "print(\"Total bytes Processed: {}\".format(bytesProcessed.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding another accumulator to above code to count number of bytes processed \n",
    "#### code change is represented using @@@@@ in comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY35",
   "language": "python",
   "name": "ml-lib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
